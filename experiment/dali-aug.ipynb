{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e29cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvidia.dali import pipeline_def\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os.path\n",
    "\n",
    "# test_data_root = os.environ[\"DALI_EXTRA_PATH\"]\n",
    "# db_folder = os.path.join(test_data_root, \"db\", \"lmdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "190e9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_transform():\n",
    "    dst_cx, dst_cy = (200, 200)\n",
    "    src_cx, src_cy = (200, 200)\n",
    "\n",
    "    # This function uses homogeneous coordinates - hence, 3x3 matrix\n",
    "\n",
    "    # translate output coordinates to center defined by (dst_cx, dst_cy)\n",
    "    t1 = np.array([[1, 0, -dst_cx], [0, 1, -dst_cy], [0, 0, 1]])\n",
    "\n",
    "    def u():\n",
    "        return np.random.uniform(-0.5, 0.5)\n",
    "\n",
    "    # apply a randomized affine transform - uniform scaling + some random\n",
    "    # distortion\n",
    "    m = np.array([[1 + u(), u(), 0], [u(), 1 + u(), 0], [0, 0, 1]])\n",
    "\n",
    "    # translate input coordinates to center (src_cx, src_cy)\n",
    "    t2 = np.array([[1, 0, src_cx], [0, 1, src_cy], [0, 0, 1]])\n",
    "\n",
    "    # combine the transforms\n",
    "    m = np.matmul(t2, np.matmul(m, t1))\n",
    "\n",
    "    # remove the last row; it's not used by affine transform\n",
    "    return m[0:2, 0:3].astype(np.float32)\n",
    "\n",
    "\n",
    "np.random.seed(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3dce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExternalInputCallable(object):\n",
    "    def __call__(self, sample_info):\n",
    "        if 0:\n",
    "            raise StopIteration()\n",
    "        # with open(\"/hdd1t/mduc/ocr/lib_ocr/experiment/vietocr_img_441026.jpg\", 'rb') as f:\n",
    "        #     file_bytes = f.read()\n",
    "        image = np.fromfile('/hdd1t/mduc/ocr/lib_ocr/experiment/vietocr_img_441026.jpg', dtype=np.uint8)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18931544",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline_def(num_threads=8, batch_size=32, device_id=0)\n",
    "def example_pipeline():\n",
    "    # This example uses external_source to provide warp matrices\n",
    "    transform = fn.external_source(\n",
    "        batch=False, source=random_transform, dtype=types.FLOAT\n",
    "    )\n",
    "\n",
    "    images = fn.external_source(\n",
    "        source=ExternalInputCallable(),\n",
    "        num_outputs=1,\n",
    "        batch=False,\n",
    "        parallel=False,\n",
    "        dtype=types.UINT8,\n",
    "    )\n",
    "\n",
    "    # The decoder takes tensors containing raw files and outputs images\n",
    "    # as 3D tensors with HWC layout\n",
    "    images = fn.decoders.image(images, output_type=types.RGB, device=\"mixed\")\n",
    "\n",
    "    warped_gpu = fn.warp_affine(\n",
    "        images,\n",
    "        transform,  # pass the transform parameters through GPU memory\n",
    "        size=(400, 400),  # specify the output size\n",
    "        # fill_value,       # not specifying `fill_value`\n",
    "        #  results in source coordinate clamping\n",
    "        interp_type=types.INTERP_LINEAR,\n",
    "    )  # use linear interpolation\n",
    "\n",
    "    warped_cpu = fn.warp_affine(\n",
    "        images,\n",
    "        matrix=transform,  # pass the transform through a named input\n",
    "        fill_value=200,\n",
    "        size=(400, 400),  # specify the output size\n",
    "        interp_type=types.INTERP_NN,\n",
    "    )  # use nearest neighbor interpolation\n",
    "\n",
    "    warped_keep_size = fn.warp_affine(\n",
    "        images,\n",
    "        transform,\n",
    "        # size,        # keep the original canvas size\n",
    "        interp_type=types.INTERP_LINEAR,\n",
    "    )  # use linear interpolation\n",
    "    images = fn.pad(images, fill_value=0)\n",
    "    images = fn.pad(warped_gpu, fill_value=0)\n",
    "    images = fn.pad(warped_cpu, fill_value=0)\n",
    "    images = fn.pad(warped_keep_size, fill_value=0)\n",
    "    return (\n",
    "        transform,\n",
    "        images,\n",
    "        warped_gpu,\n",
    "        warped_cpu,\n",
    "        warped_keep_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "681a6a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
    "\n",
    "class LightningWrapper(DALIGenericIterator):\n",
    "    def __init__(self, pipelines, *args, **kwargs):\n",
    "        super().__init__(pipelines = pipelines, *args, **kwargs)\n",
    "        self.pipelines = pipelines\n",
    "\n",
    "    def __next__(self):\n",
    "        batch = super().__next__()[0]\n",
    "        # batch[\"data\"] = batch[\"data\"].permute(0, 3, 1, 2)\n",
    "        return batch\n",
    "\n",
    "    def __code__(self):\n",
    "        return super().__code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a78016fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Critical error in pipeline:\nError in MIXED operator `nvidia.dali.fn.decoders.image`,\nwhich was used in the pipeline definition with the following traceback:\n\n  File \"/tmp/ipykernel_2072101/480016099.py\", line 18, in example_pipeline\n    images = fn.decoders.image(images, output_type=types.RGB, device=\"mixed\")\n\nencountered:\n\nError in thread 0: Unrecognized image format. Supported formats are: JPEG, PNG, BMP, TIFF, PNM, JPEG2000 and WebP.. File: \nCurrent pipeline object is no longer valid.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m pipe \u001b[38;5;241m=\u001b[39m example_pipeline(batch_size\u001b[38;5;241m=\u001b[39mbatch_size, num_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, device_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m pipe\u001b[38;5;241m.\u001b[39mbuild()\n\u001b[0;32m----> 4\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m LightningWrapper(pipe, output_map\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarped_gpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarped_cpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarped_keep_size\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m, in \u001b[0;36mLightningWrapper.__init__\u001b[0;34m(self, pipelines, *args, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pipelines, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(pipelines \u001b[38;5;241m=\u001b[39m pipelines, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipelines \u001b[38;5;241m=\u001b[39m pipelines\n",
      "File \u001b[0;32m~/.conda/envs/ocr/lib/python3.11/site-packages/nvidia/dali/plugin/pytorch/__init__.py:165\u001b[0m, in \u001b[0;36mDALIGenericIterator.__init__\u001b[0;34m(self, pipelines, output_map, size, reader_name, auto_reset, fill_last_batch, dynamic_shape, last_batch_padded, last_batch_policy, prepare_first_batch)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_first_batch:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_batch \u001b[38;5;241m=\u001b[39m DALIGenericIterator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;66;03m# call to `next` sets _ever_consumed to True but if we are just calling it from\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;66;03m# here we should set if to False again\u001b[39;00m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ever_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/ocr/lib/python3.11/site-packages/nvidia/dali/plugin/pytorch/__init__.py:180\u001b[0m, in \u001b[0;36mDALIGenericIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# Gather outputs\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_outputs()\n\u001b[1;32m    182\u001b[0m data_batches \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_gpus)]\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_gpus):\n",
      "File \u001b[0;32m~/.conda/envs/ocr/lib/python3.11/site-packages/nvidia/dali/plugin/base_iterator.py:385\u001b[0m, in \u001b[0;36m_DaliBaseIterator._get_outputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipes:\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m p\u001b[38;5;241m.\u001b[39m_check_api_type_scope(types\u001b[38;5;241m.\u001b[39mPipelineAPIType\u001b[38;5;241m.\u001b[39mITERATOR):\n\u001b[0;32m--> 385\u001b[0m             outputs\u001b[38;5;241m.\u001b[39mappend(p\u001b[38;5;241m.\u001b[39mshare_outputs())\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# in case ExternalSource returns StopIteration\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_reset \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/ocr/lib/python3.11/site-packages/nvidia/dali/pipeline.py:1297\u001b[0m, in \u001b[0;36mPipeline.share_outputs\u001b[0;34m(self, cuda_stream)\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batches_to_consume \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipe\u001b[38;5;241m.\u001b[39mShareOutputs(types\u001b[38;5;241m.\u001b[39m_raw_cuda_stream_ptr(cuda_stream))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Critical error in pipeline:\nError in MIXED operator `nvidia.dali.fn.decoders.image`,\nwhich was used in the pipeline definition with the following traceback:\n\n  File \"/tmp/ipykernel_2072101/480016099.py\", line 18, in example_pipeline\n    images = fn.decoders.image(images, output_type=types.RGB, device=\"mixed\")\n\nencountered:\n\nError in thread 0: Unrecognized image format. Supported formats are: JPEG, PNG, BMP, TIFF, PNM, JPEG2000 and WebP.. File: \nCurrent pipeline object is no longer valid."
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "pipe = example_pipeline(batch_size=batch_size, num_threads=2, device_id=0)\n",
    "pipe.build()\n",
    "dataloader = LightningWrapper(pipe, output_map=[\"transform\", \"images\", \"warped_gpu\", \"warped_cpu\", \"warped_keep_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ca52b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Pipeline' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pipe_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(pipe)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Pipeline' object is not iterable"
     ]
    }
   ],
   "source": [
    "pipe_out = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b3dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0  # change this value to see other images from the batch;\n",
    "# it must be in 0..batch_size-1 range\n",
    "\n",
    "# from synsets import imagenet_synsets\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "len_outputs = len(pipe_out) - 2\n",
    "\n",
    "captions = [\n",
    "    \"original\",\n",
    "    \"warp GPU (linear, border clamp)\",\n",
    "    \"warp CPU (nearest, fill)\",\n",
    "    \"warp GPU (keep canvas size)\",\n",
    "]\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "# plt.suptitle(imagenet_synsets[pipe_out[0].at(n)[0]], fontsize=16)\n",
    "columns = 2\n",
    "rows = int(math.ceil(len_outputs / columns))\n",
    "gs = gridspec.GridSpec(rows, columns)\n",
    "\n",
    "print(\"Affine transform matrix:\")\n",
    "print(pipe_out[1].at(n))\n",
    "\n",
    "for i in range(len_outputs):\n",
    "    plt.subplot(gs[i])\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(captions[i])\n",
    "    pipe_out_cpu = pipe_out[2 + i].as_cpu()\n",
    "    img_chw = pipe_out_cpu.at(n)\n",
    "    plt.imshow((img_chw) / 255.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
